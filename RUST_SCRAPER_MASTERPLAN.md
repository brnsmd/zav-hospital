# RUST SCRAPER MASTERPLAN ğŸª“

**Created:** 2026-01-27
**Status:** IN PROGRESS
**Tribe:** Grug (User) + Clug (Claude)

---

## OVERVIEW

Migrate Python Playwright scraper (845 lines) to pure Rust using `chromiumoxide`.
Goal: Make Boss-TUI a TRUE all-in-one binary.

---

## SPRINT STRUCTURE

Each sprint = ~100K tokens of work â†’ document â†’ git push â†’ /clear â†’ continue

---

## PHASE 1: FOUNDATION (Current Sprint) âœ… COMPLETE
**Goal:** Browser launches, connects, navigates

### Tasks:
- [x] 1.1 Add chromiumoxide to Cargo.toml (check latest version)
- [x] 1.2 Create `src/scraper/mod.rs` module structure
- [x] 1.3 Create `src/scraper/browser.rs` - browser launch/close
- [x] 1.4 Create `src/scraper/types.rs` - Patient, EnrichmentData structs
- [x] 1.5 Basic integration test - browser launches and navigates (test exists, marked #[ignore])
- [x] 1.6 Update STATUS.md

### Deliverables:
- Browser can launch (headless/headed)
- Browser can navigate to URL
- Browser can close cleanly
- Compiles without errors

### Verification:
```bash
cargo build --release
cargo test scraper
```

---

## PHASE 2: LOGIN FLOW
**Goal:** Authenticate with EMR

### Tasks:
- [ ] 2.1 Create `src/scraper/login.rs`
- [ ] 2.2 Implement form filling (username, password)
- [ ] 2.3 Implement role selection navigation
- [ ] 2.4 Implement authentication verification
- [ ] 2.5 Handle login errors gracefully
- [ ] 2.6 Test with real EMR credentials

### Deliverables:
- Can login to EMR
- Can select department role
- Returns success/failure status

### Verification:
```bash
# Manual test with relay active
boss-relay
cargo run -- --test-login
```

---

## PHASE 3: PATIENT LIST EXTRACTION
**Goal:** Scrape patient table from hospitalized list

### Tasks:
- [ ] 3.1 Create `src/scraper/patients.rs`
- [ ] 3.2 Port JavaScript table extraction (lines 234-283)
- [ ] 3.3 Implement `extract_patients_from_page()`
- [ ] 3.4 Port pagination detection JS (lines 295-345)
- [ ] 3.5 Implement `has_next_page()`
- [ ] 3.6 Implement `fetch_all_hospitalized()` with pagination loop
- [ ] 3.7 Test with real EMR

### JavaScript to Port:
```javascript
// _extract_patients_from_page (Python lines 234-283)
() => {
    const patients = [];
    const rows = document.querySelectorAll('table tbody tr');
    rows.forEach(row => {
        const cells = row.querySelectorAll('td');
        if (cells.length >= 14) {
            // ... extraction logic
        }
    });
    return patients;
}
```

### Deliverables:
- Can fetch all patients from table
- Can handle pagination (up to 50 pages)
- Returns Vec<Patient>

---

## PHASE 4: DETAIL PAGE EXTRACTION
**Goal:** Enrich patients with detail page data

### Tasks:
- [ ] 4.1 Create `src/scraper/enrichment.rs`
- [ ] 4.2 Port field extraction JS (lines 419-439)
- [ ] 4.3 Implement `fetch_patient_details(case_id)`
- [ ] 4.4 Extract all enrichment fields (birth_date, blood_type, address, etc.)
- [ ] 4.5 Handle missing fields gracefully
- [ ] 4.6 Test with real patient

### Fields to Extract:
- hospital_card_number
- ehealth_id
- birth_date
- blood_type
- address
- workplace
- marital_status
- contingent
- trauma_date
- institution
- division
- bed_type
- (and more...)

### Deliverables:
- Can navigate to patient detail page
- Can extract all enrichment fields
- Returns EnrichmentData struct

---

## PHASE 5: DIAGNOSIS EXTRACTION
**Goal:** Extract full diagnosis from Diagnosis tab

### Tasks:
- [ ] 5.1 Add diagnosis extraction to `enrichment.rs`
- [ ] 5.2 Port tab click JS (lines 542-558)
- [ ] 5.3 Port diagnosis extraction JS (lines 573-637)
- [ ] 5.4 Implement `fetch_diagnosis_from_tab(case_id)`
- [ ] 5.5 Parse ICD-10 codes
- [ ] 5.6 Extract trauma date from diagnosis text (regex)
- [ ] 5.7 Test with real patient

### JavaScript to Port:
```javascript
// Click diagnosis tab
() => {
    const tabs = document.querySelectorAll('[role="tab"]');
    for (const tab of tabs) {
        if (tab.textContent.includes('Ğ”Ñ–Ğ°Ğ³Ğ½Ğ¾Ğ·')) {
            tab.click();
            return true;
        }
    }
    return false;
}
```

### Deliverables:
- Can click Diagnosis tab
- Can extract full diagnosis text
- Can parse ICD-10 codes
- Can extract trauma_date from diagnosis

---

## PHASE 6: BATCH ENRICHMENT
**Goal:** Enrich multiple patients with rate limiting

### Tasks:
- [ ] 6.1 Implement `enrich_patients_batch()` in enrichment.rs
- [ ] 6.2 Add rate limiting (1s between patients)
- [ ] 6.3 Track enriched/failed counts
- [ ] 6.4 Handle errors gracefully (continue on failure)
- [ ] 6.5 Progress reporting
- [ ] 6.6 Test with 5-10 real patients

### Deliverables:
- Can enrich batch of patients
- Respects rate limiting
- Reports progress
- Returns EnrichmentResult

---

## PHASE 7: API INTEGRATION
**Goal:** Connect Rust scraper to Boss API routes

### Tasks:
- [ ] 7.1 Update `routes.rs` - replace Python subprocess in `start_sync`
- [ ] 7.2 Update `routes.rs` - replace Python subprocess in `enrich_patients`
- [ ] 7.3 Save scraped patients to database
- [ ] 7.4 Update sync status in database
- [ ] 7.5 Handle errors and update sync status on failure
- [ ] 7.6 Full integration test

### Deliverables:
- POST /sync uses Rust scraper
- POST /sync/enrich uses Rust scraper
- Patients saved to SQLite
- Sync status tracked

---

## PHASE 8: CLEANUP & OPTIMIZATION
**Goal:** Polish and production-ready

### Tasks:
- [ ] 8.1 Remove Python subprocess code from routes.rs
- [ ] 8.2 Add comprehensive error messages
- [ ] 8.3 Add logging throughout scraper
- [ ] 8.4 Optimize browser reuse (don't restart for enrichment)
- [ ] 8.5 Update documentation
- [ ] 8.6 Update RUST_SCRAPER_MIGRATION.md with completion status
- [ ] 8.7 Final testing with full sync + enrich cycle

### Deliverables:
- No Python dependencies for scraping
- Clean error handling
- Good logging
- Documentation updated

---

## DEPENDENCIES

### Cargo.toml additions:
```toml
# Browser automation
chromiumoxide = { version = "0.7", features = ["tokio-runtime"] }
futures = "0.3"
```

### System requirements:
- Chrome/Chromium installed
- Tailscale relay for EMR access

---

## FILE STRUCTURE (Target)

```
boss-tui/src/
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ mod.rs          # EMRScraper struct, public API
â”‚   â”œâ”€â”€ browser.rs      # Browser launch/close
â”‚   â”œâ”€â”€ login.rs        # Authentication
â”‚   â”œâ”€â”€ patients.rs     # Patient list extraction
â”‚   â”œâ”€â”€ enrichment.rs   # Detail page + diagnosis extraction
â”‚   â””â”€â”€ types.rs        # ScrapedPatient, EnrichmentData
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ routes.rs       # Updated to use Rust scraper
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
```

---

## CURRENT PROGRESS

| Phase | Status | Notes |
|-------|--------|-------|
| 1. Foundation | âœ… COMPLETE | 2026-01-27 - chromiumoxide 0.7, module structure created |
| 2. Login | âœ… COMPLETE | 2026-01-27 - login() in mod.rs, form fill, role selection |
| 3. Patient List | âœ… COMPLETE | 2026-01-27 - patients.rs, table extraction, pagination |
| 4. Detail Page | âœ… COMPLETE | 2026-01-27 - enrichment.rs, field extraction |
| 5. Diagnosis | âœ… COMPLETE | 2026-01-27 - diagnosis tab click + extraction in enrichment.rs |
| 6. Batch Enrich | âœ… COMPLETE | 2026-01-27 - enrich_patients_batch() with rate limiting |
| 7. API Integration | â¸ï¸ PAUSED | Server module not created - TUI-only for now |
| 8. Cleanup | â¸ï¸ PAUSED | Pending API integration |

### Session 2026-01-27 Summary

**Files Created:**
- `boss-tui/src/scraper/mod.rs` - 230 lines - EMRScraper struct, login, public API
- `boss-tui/src/scraper/browser.rs` - 230 lines - Browser launch, navigate, JS eval
- `boss-tui/src/scraper/types.rs` - 100 lines - ScrapedPatient, EnrichmentData, etc.
- `boss-tui/src/scraper/patients.rs` - 250 lines - Table extraction, pagination
- `boss-tui/src/scraper/enrichment.rs` - 300 lines - Detail page + diagnosis extraction

**Total: ~1100 lines of Rust** replacing 845 lines of Python

**What Works:**
- Browser launches (headless/headed) via chromiumoxide
- Login to EMR with credentials + role selection
- Extract all patients from hospitalized table (with pagination)
- Navigate to patient detail pages
- Extract enrichment fields (birth_date, blood_type, address, etc.)
- Click diagnosis tab and extract diagnosis text + ICD-10 codes
- Batch enrichment with rate limiting

**What's Missing:**
- Server module (routes.rs, db.rs) for API endpoints
- Integration with SQLite database
- TUI integration (sync commands)
- Real EMR testing

---

## CONTEXT MANAGEMENT

After each phase:
1. âœ… Code changes committed
2. âœ… This file updated with checkmarks
3. âœ… STATUS.md updated
4. âœ… Summary provided to Grug
5. âœ… Grug runs `/clear`
6. ğŸ”„ Start next phase fresh

---

## NOTES

- Chrome/Chromium still required on system
- JavaScript extraction code copied from Python (same logic)
- EMR credentials from environment variables
- Rate limiting: 1s between patient details
- Relay required for EMR access (Tailscale)

---

**HUNT BEGINS! ğŸª“**
